{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNetbasedSegmentation.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1TzgrbOz_XOt2IZuhaKLqce2EJg-ueW4P",
      "authorship_tag": "ABX9TyPsPFAXtj4Wae8NOr08IwNf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zrghassabi/U-net-Segmentation/blob/main/UNetbasedSegmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0naK3Ryxrdu"
      },
      "source": [
        "#https://www.kaggle.com/suvooo/unet-pytorch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, glob\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Function\n",
        "\n",
        "from torchvision import utils\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxOXAA8bcCMN"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE-OUuV4ypL7"
      },
      "source": [
        "# In case you need:\n",
        "!pip install -U albumentations\n",
        "# import albumentations \n",
        "# from albumentations.pytorch import ToTensorV2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSftDVelWJ7e"
      },
      "source": [
        "#print(\"train data size: \", len(glob.glob(\"../train_masks/*\")))\n",
        "#data = pd.read_csv(\"../train_masks.csv\")\n",
        "#data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUW7QeTTjuL9"
      },
      "source": [
        "# use Dataset from kaggle directly\n",
        "# https://www.analyticsvidhya.com/blog/2021/06/how-to-load-kaggle-datasets-directly-into-google-colab/\n",
        "! pip install kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C4iodp4kvAD"
      },
      "source": [
        "#! mkdir ~/.kaggle\n",
        "#/kaggle.json\n",
        "! cp /kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlkuhwCHmy2_"
      },
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLaEp2Egslft"
      },
      "source": [
        "#unzipping the files\n",
        "!unzip '/content/carvana-image-masking-challenge.zip' -d './content/'\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxUICXndlm3O"
      },
      "source": [
        "#https://www.kaggle.com/c/carvana-image-masking-challenge/data\n",
        "#Accept Rules of competition before you doanlod data\n",
        "!kaggle competitions download -c carvana-image-masking-challenge"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNb_vY9Br_J8"
      },
      "source": [
        "#print(\"train data size: \", len(glob.glob(\"../train_masks/*\")))\n",
        "#data = pd.read_csv(\"../train_masks.csv\")\n",
        "#data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEemJQNwaz38"
      },
      "source": [
        "fig = plt.figure(figsize=(10,10))\n",
        "img = np.array(Image.open(\"/kaggle/working/train/11acc40dc0ea_03.jpg\"))\n",
        "img_mask = np.array(Image.open(\"/kaggle/working/train_masks/11acc40dc0ea_03_mask.gif\"))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(img)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(img_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-86KoJOcF3D"
      },
      "source": [
        "#Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVIvwgpCa04t"
      },
      "source": [
        "class CarvanaDataset(Dataset):\n",
        "    def __init__(self, root_dir, train_img_list):\n",
        "        super().__init__()\n",
        "        self.img_dir = os.path.join(root_dir, \"train\")\n",
        "        self.mask_dir = os.path.join(root_dir, \"train_masks\")\n",
        "        self.img_list = train_img_list\n",
        "        self.img_transform = A.Compose([\n",
        "            A.Resize(256, 256),\n",
        "            A.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                        std=[0.229, 0.224, 0.225]),\n",
        "            ToTensorV2()\n",
        "        ])\n",
        "        self.mask_transform = A.Compose([\n",
        "            A.Resize(256, 256),\n",
        "            ToTensorV2()\n",
        "        ])\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_abs_path = os.path.join(self.img_dir, self.img_list[idx])\n",
        "        mask_abs_path = os.path.join(\n",
        "                self.mask_dir, \n",
        "                self.img_list[idx].split(\".\")[0] + \"_mask.gif\")\n",
        "    \n",
        "        img = np.array(Image.open(img_abs_path))\n",
        "        mask = np.array(Image.open(mask_abs_path))\n",
        "        \n",
        "        img = self.img_transform(image=img)[\"image\"]\n",
        "        mask = self.mask_transform(image=mask)[\"image\"]\n",
        "        \n",
        "        return img, mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtRXdsoSbye-"
      },
      "source": [
        "train_img_list = pd.read_csv(\"/kaggle/working/train_masks.csv\")['img']\n",
        "dataset = CarvanaDataset(\"/kaggle/working\", train_img_list)\n",
        "\n",
        "train_size = int(len(train_img_list) * 0.8)\n",
        "val_size = len(train_img_list) - train_size\n",
        "\n",
        "train_set, val_set = torch.utils.data.random_split(\n",
        "                    dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=8, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZC8LcgWcMUA"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRKV16vCa4yP"
      },
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Conv2d(out_channels, out_channels, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.main(x)\n",
        "\n",
        "class Down(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            DoubleConv(in_channels, out_channels),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.main(x)\n",
        "    \n",
        "    \n",
        "class Up(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        \n",
        "        mid_channels = in_channels // 2\n",
        "        self.up_conv =  nn.ConvTranspose2d(in_channels, mid_channels, \n",
        "                               kernel_size=2, stride=2, padding=0)\n",
        "        \n",
        "        self.double_conv =  DoubleConv(mid_channels*2, out_channels)\n",
        "\n",
        "        \n",
        "    def forward(self, x, copy):\n",
        "        x = self.up_conv(x)\n",
        "        #pad_lower = (copy.size()[2] - x.size()[2]) // 2\n",
        "        #pad_upper = copy.size()[2] - pad_lower\n",
        "        #copy = copy[:, :, pad_lower:pad_upper, pad_lower:pad_upper]\n",
        "        x = torch.cat([copy, x], dim=1)\n",
        "        \n",
        "        return self.double_conv(x)\n",
        "    \n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, img_channels, num_classes, features=64):\n",
        "        super().__init__()\n",
        "        self.max_pool = nn.MaxPool2d(2)\n",
        "        \n",
        "        self.dc1 = DoubleConv(img_channels, features)\n",
        "        self.dc2 = DoubleConv(features, features*2)\n",
        "        self.dc3 = DoubleConv(features*2, features*4)\n",
        "        self.dc4 = DoubleConv(features*4, features*8)\n",
        "        self.dc5 = DoubleConv(features*8, features*16)\n",
        "        \n",
        "        self.up1 = Up(features*16, features*8)\n",
        "        self.up2 = Up(features*8, features*4)\n",
        "        self.up3 = Up(features*4, features*2)\n",
        "        self.up4 = Up(features*2, features)\n",
        "        \n",
        "        self.final = nn.Conv2d(features, num_classes, 1, 1, 0)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        #contracting path\n",
        "        d1 = self.dc1(x)\n",
        "        d2 = self.dc2(self.max_pool(d1))\n",
        "        d3 = self.dc3(self.max_pool(d2))\n",
        "        d4 = self.dc4(self.max_pool(d3))\n",
        "        x = self.dc5(self.max_pool(d4)) #bottlenek\n",
        "        \n",
        "        #expansive path\n",
        "        x = self.up1(x, d4)\n",
        "        x = self.up2(x, d3)\n",
        "        x = self.up3(x, d2)\n",
        "        x = self.up4(x, d1)\n",
        "        return self.final(x)\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k7SFWh8b6oH"
      },
      "source": [
        "#Train and Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7A12iOpbMFL"
      },
      "source": [
        "class ImageSegment(object):\n",
        "    def __init__(self, train_loader, val_loader, device):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.num_classes = 1\n",
        "        self.img_channels = 3\n",
        "        self.unet = UNet(self.img_channels, self.num_classes).to(device)\n",
        "        self.optim = optim.RMSprop(\n",
        "            self.unet.parameters(), \n",
        "            lr=1e-4, momentum=0.9, weight_decay=1e-8)\n",
        "        \n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            self.optim, \n",
        "            \"min\" if self.num_classes > 1 else \"max\", \n",
        "            patience=2)\n",
        "        \n",
        "        self.criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def dice_calc(self, gt, pred) :\n",
        "        pred = torch.sigmoid(pred)\n",
        "        pred = ((pred) >= .5).float()\n",
        "        dice_score = (2 * (pred * gt).sum()) / ((pred + gt).sum() + 1e-8)\n",
        "        return dice_score\n",
        "    \n",
        "    def train(self, num_epochs=1):\n",
        "        loop = tqdm(train_loader, leave=False, total=train_loader.__len__())\n",
        "        total_loss = 0\n",
        "        dice_score = 0\n",
        "        \n",
        "        for epoch in range(num_epochs):\n",
        "            for img, mask in loop:\n",
        "                img, mask = img.to(self.device), mask.to(self.device)\n",
        "\n",
        "                self.optim.zero_grad()\n",
        "                mask_pred = self.unet(img)\n",
        "                loss = self.criterion(mask_pred, mask.float())\n",
        "                total_loss += loss.item()\n",
        "                loss.backward()\n",
        "                self.optim.step()\n",
        "\n",
        "                #buji na\n",
        "                run_DS = self.dice_calc(mask, mask_pred)\n",
        "                dice_score += run_DS\n",
        "\n",
        "                loop.set_postfix(loss=loss.item())\n",
        "\n",
        "            print(\"Epoch %d| loss: %f | dice score %f\" % (epoch+1, total_loss, dice_score))\n",
        "            \n",
        "    def test(self):\n",
        "        with torch.no_grad():\n",
        "            images ,masks =next(iter(self.val_loader))\n",
        "            images = images.to(self.device)\n",
        "            masks  = masks.to(self.device)\n",
        "\n",
        "            mask_pred = self.unet(images)\n",
        "\n",
        "            img = mask_pred.cpu().numpy()\n",
        "            masks = masks.cpu().numpy()\n",
        "            masks_2 = (masks > 0.5).astype(int)\n",
        "\n",
        "            fig, axes = plt.subplots(1, 3, figsize=(15, 15))\n",
        "\n",
        "            axes[0].imshow(masks[0][0])\n",
        "            axes[0].set_title('Ground Truth Mask')\n",
        "\n",
        "            axes[1].imshow(img[0][0])\n",
        "            axes[1].set_title('Prababilistic Mask')\n",
        "\n",
        "            axes[2].imshow(masks_2[0][0])\n",
        "            axes[2].set_title('Probabilistic Mask threshold')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BW8Du8vbSqc"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "img_seq = ImageSegment(train_loader, val_loader, device)\n",
        "img_seq.train(num_epochs=7)\n",
        "img_seq.test()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}