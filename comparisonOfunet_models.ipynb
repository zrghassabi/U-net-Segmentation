{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "comparisonOfunet_models.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOrEc4aiFh/HM++v8jHLTwO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zrghassabi/U-net-Segmentation/blob/main/comparisonOfunet_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuvK_vBMrVPQ"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torch.nn import functional as F\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G52Acbck-pTc"
      },
      "source": [
        "#Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9qk7avR-wQM"
      },
      "source": [
        "#Unet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fi4_OqnRtMMN"
      },
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3)\n",
        "        self.relu  = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.conv2(self.relu(self.conv1(x)))\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, chs=(1,64,128,256,512,1024)):\n",
        "        super().__init__()\n",
        "        self.enc_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)])\n",
        "        self.pool       = nn.MaxPool2d(2)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        ftrs = []\n",
        "        for block in self.enc_blocks:\n",
        "            x = block(x)\n",
        "            ftrs.append(x)\n",
        "            x = self.pool(x)\n",
        "        return ftrs\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, chs=(1024, 512, 256, 128, 64)):\n",
        "        super().__init__()\n",
        "        self.chs         = chs\n",
        "        self.upconvs    = nn.ModuleList([nn.ConvTranspose2d(chs[i], chs[i+1], 2, 2) for i in range(len(chs)-1)])\n",
        "        self.dec_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)]) \n",
        "        \n",
        "    def forward(self, x, encoder_features):\n",
        "        for i in range(len(self.chs)-1):\n",
        "            x        = self.upconvs[i](x)\n",
        "            enc_ftrs = self.crop(encoder_features[i], x)\n",
        "            x        = torch.cat([x, enc_ftrs], dim=1)\n",
        "            x        = self.dec_blocks[i](x)\n",
        "        return x\n",
        "    \n",
        "    def crop(self, enc_ftrs, x):\n",
        "        _, _, H, W = x.shape\n",
        "        enc_ftrs   = torchvision.transforms.CenterCrop([H, W])(enc_ftrs)\n",
        "        return enc_ftrs\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, enc_chs=(1,64,128,256,512,1024), dec_chs=(1024, 512, 256, 128, 64), num_class=1, retain_dim=True, out_sz=(874,512)):\n",
        "        super().__init__()\n",
        "        self.encoder     = Encoder(enc_chs)\n",
        "        self.decoder     = Decoder(dec_chs)\n",
        "        self.head        = nn.Conv2d(dec_chs[-1], num_class, 1)\n",
        "        self.retain_dim  = retain_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc_ftrs = self.encoder(x)\n",
        "        out      = self.decoder(enc_ftrs[::-1][0], enc_ftrs[::-1][1:])\n",
        "        out      = self.head(out)\n",
        "        if self.retain_dim:\n",
        "            out = F.interpolate(out, (874,512)) #out_rz=(874,512)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma4rVFfGtZLp"
      },
      "source": [
        "unet = UNet()\n",
        "x    = torch.randn(1, 1, 874, 512)\n",
        "unet(x).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxLVUTTj-2hv"
      },
      "source": [
        "#Deep U chape CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CznP3EA395u2"
      },
      "source": [
        "class DUDnCNN(nn.Module):\n",
        "\n",
        "    def __init__(self, D=6, C=64):\n",
        "        super().__init__()\n",
        "        self.D = D\n",
        "\n",
        "        # compute k(max_pool) and l(max_unpool)\n",
        "        k = [0]\n",
        "        k.extend([i for i in range(D//2)])\n",
        "        k.extend([k[-1] for _ in range(D//2, D+1)])\n",
        "        l = [0 for _ in range(D//2+1)]\n",
        "        l.extend([i for i in range(D+1-(D//2+1))])\n",
        "        l.append(l[-1])\n",
        "\n",
        "        # holes and dilations for convolution layers\n",
        "        holes = [2**(kl[0]-kl[1])-1 for kl in zip(k, l)]\n",
        "        dilations = [i+1 for i in holes]\n",
        "\n",
        "        # convolution layers\n",
        "        self.conv = nn.ModuleList()\n",
        "        self.conv.append(\n",
        "            nn.Conv2d(1, C, 3, padding=dilations[0], dilation=dilations[0])) #nn.Conv2d(3 for 3 channels\n",
        "        self.conv.extend([nn.Conv2d(C, C, 3, padding=dilations[i+1],  #self.conv.extend([nn.Conv2d(C, C, 3, \n",
        "                                    dilation=dilations[i+1]) for i in range(D)])\n",
        "        self.conv.append(\n",
        "            nn.Conv2d(C, 1, 3, padding=dilations[-1], dilation=dilations[-1]))    #nn.Conv2d(C, 3, 3,\n",
        "        # apply He's initialization\n",
        "        for i in range(len(self.conv[:-1])):\n",
        "            nn.init.kaiming_normal_(\n",
        "                self.conv[i].weight.data, nonlinearity='relu') #relu #leaky_relu\n",
        "\n",
        "        # batch normalization\n",
        "        self.bn = nn.ModuleList()\n",
        "        self.bn.extend([nn.BatchNorm2d(C, C) for _ in range(D)])\n",
        "        # initialize the weights of the Batch normalization layers\n",
        "        for i in range(D):\n",
        "            nn.init.constant_(self.bn[i].weight.data, 1.25 * np.sqrt(C))\n",
        "\n",
        "    def forward(self, x):\n",
        "        D = self.D\n",
        "        h = F.relu(self.conv[0](x))\n",
        "        h_buff = []\n",
        "\n",
        "        for i in range(D//2 - 1):\n",
        "            torch.backends.cudnn.benchmark = True\n",
        "            h = self.conv[i+1](h)\n",
        "            torch.backends.cudnn.benchmark = False\n",
        "            h = F.relu(self.bn[i](h))\n",
        "            h_buff.append(h)\n",
        "\n",
        "        for i in range(D//2 - 1, D//2 + 1):\n",
        "            torch.backends.cudnn.benchmark = True\n",
        "            h = self.conv[i+1](h)\n",
        "            torch.backends.cudnn.benchmark = False\n",
        "            h = F.relu(self.bn[i](h))\n",
        "\n",
        "        for i in range(D//2 + 1, D):\n",
        "            j = i - (D//2 + 1) + 1\n",
        "            torch.backends.cudnn.benchmark = True\n",
        "            h = self.conv[i+1]((h + h_buff[-j]) / np.sqrt(2))\n",
        "            torch.backends.cudnn.benchmark = False\n",
        "            h = F.relu(self.bn[i](h))\n",
        "\n",
        "        y = self.conv[D+1](h) + x\n",
        "        return y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHbxE3Bh-CCu"
      },
      "source": [
        "DeepUshapeCNN = DUDnCNN()\n",
        "x    = torch.randn(1, 1, 874, 512)\n",
        "DeepUshapeCNN(x).shape\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}